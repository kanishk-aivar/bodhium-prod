# Task Retry System Proposal

## Overview

This proposal outlines the implementation of a manual retry system for failed tasks in the Bodhium orchestration system. The system allows users to retry individual failed tasks while maintaining a complete audit trail.

## Core Requirements

### Database Schema Changes

#### 1. New `failed_tasks` Table
```sql
-- Create failed_tasks table (similar to llmtasks but allows multiple entries per task_id)
CREATE TABLE failed_tasks (
    id SERIAL PRIMARY KEY,  -- Auto-increment primary key
    task_id UUID,  -- Can have multiple entries for same task_id (retry history)
    job_id UUID,
    query_id BIGINT,
    product_id BIGINT,
    product_name TEXT,
    query TEXT,
    model VARCHAR(50),
    status VARCHAR(20),
    s3_output_path TEXT,
    execution_time_seconds INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_id UUID  -- New column
);
```

#### 2. Add `session_id` to `llmtasks` Table
```sql
-- Add session_id column to existing llmtasks table
ALTER TABLE llmtasks ADD COLUMN session_id UUID;

-- Add index for performance
CREATE INDEX idx_llmtasks_session_id ON llmtasks(session_id);
CREATE INDEX idx_failed_tasks_session_id ON failed_tasks(session_id);
```

### System Architecture Changes

#### 1. Orchestrator Enhancements

**New Responsibilities:**
- Generate `session_id` for each orchestration request
- Generate `task_id` for each worker invocation (moved from workers)
- Handle retry requests by querying database and triggering specific workers
- Pass `session_id` and `task_id` to all worker Lambdas

**Retry Request Input:**
```json
{
  "retry_task": "task_id_uuid_from_llmtasks"
}
```

**Retry Logic Flow:**
1. Receive retry request with `task_id`
2. Query `llmtasks` table to find task record
3. Verify task status is `failed`
4. Identify appropriate worker using `model` column
5. Trigger only the specific worker Lambda with existing task details
6. Worker will handle copying to `failed_tasks` and overwriting the record

#### 2. Worker Lambda Changes

**New Parameters Received:**
- `task_id`: Generated by orchestrator (not worker)
- `session_id`: Session identifier for grouping related tasks

**Enhanced Logic:**
```python
def lambda_handler(event, context):
    # Extract new parameters
    task_id = event.get('task_id')
    session_id = event.get('session_id')
    
    # Check if task_id already exists (retry scenario)
    existing_task = get_existing_task(task_id)
    
    if existing_task:
        # This is a retry - copy existing record to failed_tasks
        copy_to_failed_tasks(existing_task)
        logger.info(f"Copied existing task {task_id} to failed_tasks for retry")
    
    # Process the task (will overwrite existing record)
    # ... existing worker logic ...
    
    # Store with session_id
    create_or_update_llm_task(
        task_id=task_id,
        session_id=session_id,
        # ... other parameters
    )
```

## Implementation Plan

### Phase 1: Database Migration
```sql
-- Migration Script: 001_add_retry_system.sql
BEGIN;
  -- Add session_id to llmtasks
  ALTER TABLE llmtasks ADD COLUMN session_id UUID;
  
  -- Create failed_tasks table (allows multiple entries per task_id for retry history)
  CREATE TABLE failed_tasks (
    id SERIAL PRIMARY KEY,
    task_id UUID,
    job_id UUID,
    query_id BIGINT,
    product_id BIGINT,
    product_name TEXT,
    query TEXT,
    model VARCHAR(50),
    status VARCHAR(20),
    s3_output_path TEXT,
    execution_time_seconds INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_id UUID
  );
  
  -- Add indexes for performance
  CREATE INDEX idx_llmtasks_session_id ON llmtasks(session_id);
  CREATE INDEX idx_llmtasks_status ON llmtasks(status);
  CREATE INDEX idx_failed_tasks_task_id ON failed_tasks(task_id);
  CREATE INDEX idx_failed_tasks_session_id ON failed_tasks(session_id);
  CREATE INDEX idx_failed_tasks_created_at ON failed_tasks(created_at);
COMMIT;
```

### Phase 2: Orchestrator Updates

#### Modified `orchestrator.py`:
```python
def lambda_handler(event, context):
    # Check if this is a retry request
    if "retry_task" in event:
        return handle_retry_request(event, context)
    
    # Normal orchestration with session_id generation
    session_id = str(uuid.uuid4())
    # ... existing logic with session_id passed to workers

def handle_retry_request(event, context):
    retry_task_id = event["retry_task"]
    
    # Query llmtasks to find the task
    task_record = query_task_by_id(retry_task_id)
    
    if not task_record:
        return {"error": f"Task {retry_task_id} not found"}
    
    if task_record["status"] != "failed":
        return {"error": f"Task {retry_task_id} is not in failed status"}
    
    # Determine worker based on model column
    worker_arn = get_worker_arn_by_model(task_record["model"])
    
    if not worker_arn:
        return {"error": f"No worker found for model {task_record['model']}"}
    
    # Trigger the specific worker with existing task data
    payload = {
        "task_id": retry_task_id,  # Same task_id (will overwrite)
        "session_id": task_record["session_id"],
        "job_id": task_record["job_id"],
        "query_id": task_record["query_id"],
        "product_id": task_record["product_id"],
        "query": task_record["query"]
    }
    
    trigger_lambda(worker_arn, payload, task_record["job_id"], task_record["query_id"])
    
    return {
        "statusCode": 200,
        "body": {
            "message": f"Retry initiated for task {retry_task_id}",
            "worker": task_record["model"],
            "task_id": retry_task_id
        }
    }

def get_worker_arn_by_model(model):
    """Map model name to worker ARN"""
    model_to_arn = {
        "chatgpt": TARGETS["chatgpt"],
        "aio": TARGETS["aio"],
        "aim": TARGETS["aim"],
        "perplexity": TARGETS["perplexity"]
    }
    return model_to_arn.get(model.lower())
```

### Phase 3: Worker Lambda Updates

#### Common Changes for All Workers:
```python
def lambda_handler(event, context):
    # Extract orchestrator-provided IDs
    task_id = event.get('task_id', str(uuid.uuid4()))  # Fallback for compatibility
    session_id = event.get('session_id')
    
    # Check for existing task (retry scenario)
    existing_task = get_task_by_id(task_id)
    
    if existing_task:
        # Copy to failed_tasks before overwriting
        copy_to_failed_tasks_table(existing_task)
        logger.info(f"Retry detected: Copied task {task_id} to failed_tasks")
    
    # Continue with normal processing
    # ... existing worker logic ...
    
    # Create/update task with session_id
    create_llm_task(
        task_id=task_id,
        session_id=session_id,
        # ... other parameters
    )

def get_task_by_id(task_id):
    """Query llmtasks table for existing task"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            "SELECT * FROM llmtasks WHERE task_id = %s",
            (task_id,)
        )
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        return result
    except Exception as e:
        logger.error(f"Failed to query existing task: {e}")
        return None

def copy_to_failed_tasks_table(task_record):
    """Copy task record to failed_tasks table"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO failed_tasks 
            (task_id, job_id, query_id, product_id, product_name, query, 
             model, status, s3_output_path, execution_time_seconds, 
             created_at, updated_at, session_id)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """,
            task_record  # Assuming task_record is a tuple with all values
        )
        conn.commit()
        cursor.close()
        conn.close()
        logger.info(f"Successfully copied task {task_record[0]} to failed_tasks")
    except Exception as e:
        logger.error(f"Failed to copy task to failed_tasks: {e}")
```

## API Endpoints

### Normal Orchestration (Enhanced)
```
POST /orchestrate
{
  "job_id": "uuid",
  "selected_queries": [...]
}

Response:
{
  "statusCode": 202,
  "body": {
    "session_id": "generated_uuid",
    "job_id": "uuid",
    "message": "Job submitted successfully"
  }
}
```

### Retry Endpoint (New)
```
POST /orchestrate
{
  "retry_task": "task_id_from_llmtasks"
}

Response:
{
  "statusCode": 200,
  "body": {
    "message": "Retry initiated for task {task_id}",
    "worker": "chatgpt",
    "task_id": "uuid"
  }
}
```

## Data Flow

### Normal Flow
1. **Orchestrator**: Generate `session_id` and `task_id` for each worker call
2. **Workers**: Receive IDs, process tasks, store in `llmtasks` with `session_id`

### Retry Flow
1. **User**: Submit retry request with `task_id`
2. **Orchestrator**: 
   - Query `llmtasks` for task details
   - Verify status is `failed`
   - Identify worker using `model` column
   - Trigger specific worker with same `task_id`
3. **Worker**:
   - Detect existing `task_id` in database
   - Copy current record to `failed_tasks` (creates new entry each retry)
   - Process task and overwrite record in `llmtasks`

### Multiple Retry Scenario
If a task fails and gets retried multiple times:

**Example: Task retried 4 times**
1. **Initial failure**: Task status = `failed` in `llmtasks`
2. **1st retry**: Copy to `failed_tasks` (#1) → Process → May succeed or fail again
3. **2nd retry**: Copy to `failed_tasks` (#2) → Process → May succeed or fail again  
4. **3rd retry**: Copy to `failed_tasks` (#3) → Process → May succeed or fail again
5. **4th retry**: Copy to `failed_tasks` (#4) → Process → Final attempt

**Result**: 4 records in `failed_tasks` table, each capturing the task state at retry time

## Benefits

1. **Simple Implementation**: Minimal changes to existing architecture
2. **Complete Audit Trail**: `failed_tasks` preserves every retry attempt - 4 retries = 4 historical records
3. **Manual Control**: Retries only happen when explicitly requested
4. **Task Overwriting**: Clean approach without creating duplicate records in `llmtasks`
5. **Session Tracking**: `session_id` groups related tasks for analytics
6. **Precise Targeting**: Only retry the specific failed worker, not all workers
7. **Comprehensive History**: Track patterns in task failures across multiple retry attempts
8. **Debugging Support**: Each failed attempt preserved with full context for troubleshooting

## Database Schema Reference

### Updated `llmtasks` Table
```sql
CREATE TABLE llmtasks (
    task_id UUID PRIMARY KEY,
    job_id UUID,
    query_id BIGINT,
    product_id BIGINT,
    product_name TEXT,
    query TEXT,
    model VARCHAR(50),
    status VARCHAR(20),
    s3_output_path TEXT,
    execution_time_seconds INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_id UUID  -- NEW COLUMN
);
```

### New `failed_tasks` Table
```sql
CREATE TABLE failed_tasks (
    id SERIAL PRIMARY KEY,  -- Auto-increment ID as primary key
    task_id UUID,  -- NOT unique - same task_id can have multiple entries
    job_id UUID,
    query_id BIGINT,
    product_id BIGINT,
    product_name TEXT,
    query TEXT,
    model VARCHAR(50),
    status VARCHAR(20),
    s3_output_path TEXT,
    execution_time_seconds INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_id UUID
);

-- Indexes for querying retry history
CREATE INDEX idx_failed_tasks_task_id ON failed_tasks(task_id);
CREATE INDEX idx_failed_tasks_session_id ON failed_tasks(session_id);
CREATE INDEX idx_failed_tasks_created_at ON failed_tasks(created_at);
```

### Example: Failed Tasks Audit Trail
```sql
-- Query retry history for a specific task
SELECT task_id, status, created_at, model 
FROM failed_tasks 
WHERE task_id = 'some-uuid' 
ORDER BY created_at ASC;

-- Result shows 4 retry attempts:
-- task_id              | status | created_at          | model
-- some-uuid           | failed | 2024-01-01 10:00:00 | chatgpt
-- some-uuid           | failed | 2024-01-01 11:00:00 | chatgpt  
-- some-uuid           | failed | 2024-01-01 12:00:00 | chatgpt
-- some-uuid           | failed | 2024-01-01 13:00:00 | chatgpt
```

## Testing Strategy

### Unit Tests
- Orchestrator retry logic with various task states
- Worker retry detection and failed_tasks copying
- Database query functions

### Integration Tests
- End-to-end retry flow
- Concurrent retry attempts
- Database consistency validation

### Manual Testing Scenarios
1. Retry a failed task → Success
2. Retry a successful task → Error  
3. Retry a non-existent task → Error
4. **Multiple Retry Test**: Retry same task 4 times → Verify 4 records in failed_tasks
5. Verify failed_tasks audit trail with timestamps
6. Confirm task overwriting behavior in llmtasks
7. Query retry history: `SELECT * FROM failed_tasks WHERE task_id = 'uuid' ORDER BY created_at`

## Deployment Plan

1. **Database Migration**: Apply schema changes during maintenance window
2. **Worker Updates**: Deploy updated worker Lambdas (backward compatible)
3. **Orchestrator Update**: Deploy enhanced orchestrator with retry logic  
4. **Documentation**: Update API documentation with retry endpoint
5. **Monitoring**: Add CloudWatch metrics for retry operations

## Risk Mitigation

1. **Database Migration**: Test on staging environment first
2. **Backward Compatibility**: Ensure workers handle missing `session_id`
3. **Concurrent Retries**: Database constraints prevent duplicate failed_tasks entries
4. **Error Handling**: Comprehensive error responses for all failure scenarios
